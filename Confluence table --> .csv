import requests
from bs4 import BeautifulSoup
import csv

# --- CONFIGURATION ---
CONFLUENCE_BASE_URL = "https://your-domain.atlassian.net/wiki"
PAGE_ID = "123456789"  # Replace with your Confluence page ID
AUTH_EMAIL = "your.email@example.com"
API_TOKEN = "your_api_token_here"  # Get from https://id.atlassian.com/manage/api-tokens
CSV_OUTPUT_FILE = "exported_table.csv"

# --- FETCH PAGE CONTENT ---
url = f"{CONFLUENCE_BASE_URL}/rest/api/content/{PAGE_ID}?expand=body.storage"
response = requests.get(url, auth=(AUTH_EMAIL, API_TOKEN))

if response.status_code != 200:
    raise Exception(f"Failed to fetch content: {response.status_code} - {response.text}")

html_content = response.json()["body"]["storage"]["value"]

# --- PARSE HTML TABLE ---
soup = BeautifulSoup(html_content, "html.parser")
table = soup.find("table")

if not table:
    raise Exception("No table found on the page.")

# --- EXTRACT TABLE DATA ---
rows = table.find_all("tr")
parsed_table = []

for row in rows:
    cols = row.find_all(["td", "th"])
    parsed_table.append([col.get_text(strip=True) for col in cols])

# --- WRITE TO CSV ---
with open(CSV_OUTPUT_FILE, "w", newline="", encoding="utf-8") as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(parsed_table)

print(f"Table exported to {CSV_OUTPUT_FILE}")
